{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9b1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07d20148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"data/IMDB Dataset.csv\", nrows=20)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afd5a6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa1b7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>Quite what the producers of this appalling ada...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>My favourite police series of all time turns t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>Beautiful film, pure Cassavetes style. Gena Ro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "3537  Quite what the producers of this appalling ada...  negative\n",
       "3769  My favourite police series of all time turns t...  positive\n",
       "4391  Beautiful film, pure Cassavetes style. Gena Ro...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['review'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd0f73ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     5000 non-null   object\n",
      " 1   sentiment  5000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 78.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe9b6f",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9f695aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower casing\n",
    "data['review'] = data['review'].str.lower()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "66faeb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    one of the other reviewers has mentioned that ...\n",
       "1    a wonderful little production. the filming tec...\n",
       "2    i thought this was a wonderful way to spend ti...\n",
       "3    basically there's a family where a little boy ...\n",
       "4    petter mattei's \"love in the time of money\" is...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing HTML tags\n",
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r\"\",text)\n",
    "data['review'] = data['review'].apply(remove_html_tags)\n",
    "data.review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3638ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing URLS\n",
    "import re\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r\"\", text)\n",
    "data['review'] = data['review'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db99dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation\n",
    "import string\n",
    "exclude = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('','',exclude))\n",
    "data['review'] =  data['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "232138d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spelling correction\n",
    "from textblob import TextBlob\n",
    "\n",
    "def correct_spell(text):\n",
    "    textblob = TextBlob(text)\n",
    "    return str(TextBlob(text).correct())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ca4a53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    one of the other reviews has mentioned that af...\n",
       "1    a wonderful little production the filling tech...\n",
       "2    i thought this was a wonderful way to spend ti...\n",
       "3    basically there a family where a little boy ja...\n",
       "4    letter matters love in the time of money is a ...\n",
       "5    probably my alliee favorite movie a story of h...\n",
       "6    i sure would like to see a resurrection of a u...\n",
       "7    this show was an amazing fresh  innovative ide...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'] = data['review'].apply(correct_spell)\n",
    "data.review.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "64e84a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    one    reviews  mentioned   watching  1 oz epi...\n",
       "1     wonderful little production  filling techniqu...\n",
       "2     thought    wonderful way  spend time    hot s...\n",
       "3    basically   family   little boy jake thinks   ...\n",
       "4    letter matters love   time  money   usually st...\n",
       "5    probably  alliee favorite movie  story  helple...\n",
       "6     sure would like  see  resurrection    dated s...\n",
       "7     show   amazing fresh innovative idea      fir...\n",
       "8    encouraged   positive comments   film     look...\n",
       "9      like original gut wrenching laughter   like ...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop words\n",
    "from nltk.corpus import stopwords\n",
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append(\"\")\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)\n",
    "\n",
    "data['review'] = data['review'].apply(remove_stopwords)\n",
    "data['review'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0cde2df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one    reviews  mentioned   watching  1 oz epi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, reviews, mentioned, watching, 1, oz, epi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production  filling techniqu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonderful, little, production, filling, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought    wonderful way  spend time    hot s...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically   family   little boy jake thinks   ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, family, little, boy, jake, thinks,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>letter matters love   time  money   usually st...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[letter, matters, love, time, money, usually, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one    reviews  mentioned   watching  1 oz epi...  positive   \n",
       "1   wonderful little production  filling techniqu...  positive   \n",
       "2   thought    wonderful way  spend time    hot s...  positive   \n",
       "3  basically   family   little boy jake thinks   ...  negative   \n",
       "4  letter matters love   time  money   usually st...  positive   \n",
       "\n",
       "                                              tokens  \n",
       "0  [one, reviews, mentioned, watching, 1, oz, epi...  \n",
       "1  [wonderful, little, production, filling, techn...  \n",
       "2  [thought, wonderful, way, spend, time, hot, su...  \n",
       "3  [basically, family, little, boy, jake, thinks,...  \n",
       "4  [letter, matters, love, time, money, usually, ...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "data['tokens'] = data['review'].apply(word_tokenize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5019bf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one    reviews  mentioned   watching  1 oz epi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, review, mention, watch, 1, oz, episod, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production  filling techniqu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonder, littl, product, fill, techniqu, assum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought    wonderful way  spend time    hot s...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically   family   little boy jake thinks   ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basic, famili, littl, boy, jake, think, combi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>letter matters love   time  money   usually st...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[letter, matter, love, time, money, usual, stu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one    reviews  mentioned   watching  1 oz epi...  positive   \n",
       "1   wonderful little production  filling techniqu...  positive   \n",
       "2   thought    wonderful way  spend time    hot s...  positive   \n",
       "3  basically   family   little boy jake thinks   ...  negative   \n",
       "4  letter matters love   time  money   usually st...  positive   \n",
       "\n",
       "                                              tokens  \n",
       "0  [one, review, mention, watch, 1, oz, episod, h...  \n",
       "1  [wonder, littl, product, fill, techniqu, assum...  \n",
       "2  [thought, wonder, way, spend, time, hot, summe...  \n",
       "3  [basic, famili, littl, boy, jake, think, combi...  \n",
       "4  [letter, matter, love, time, money, usual, stu...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stemmer(tokens):\n",
    "    return [ps.stem(word) for word in tokens]\n",
    "\n",
    "data['tokens'] = data['tokens'].apply(stemmer)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd9a5d1",
   "metadata": {},
   "source": [
    "## Feature Extraction/ Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "04e6a97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595\n"
     ]
    }
   ],
   "source": [
    "# Number of words in the corpus\n",
    "corpus = []\n",
    "for i in data['tokens']:\n",
    "    corpus.extend(i)\n",
    "    \n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bc73172c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary\n",
    "vocab = list(set(corpus))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b41b32",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6b990764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f9e3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = cv.fit_transform(data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "99a19e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('one', 609), ('reviews', 722), ('mentioned', 551), ('watching', 972), ('oz', 617), ('episode', 268), ('hooked', 404), ('right', 726), ('exactly', 277), ('happened', 386), ('metre', 555), ('first', 321), ('thing', 895), ('struck', 857), ('brutally', 114), ('unflinching', 942), ('scenes', 753), ('violence', 956), ('set', 778), ('word', 994), ('go', 356), ('trust', 934), ('show', 793), ('faint', 295), ('hearted', 393), ('timid', 912), ('pulls', 685), ('punched', 686), ('regards', 705), ('drugs', 239), ('sex', 780), ('hardware', 390), ('classic', 147), ('use', 945), ('words', 995), ('called', 119), ('nickname', 594), ('given', 351), ('onward', 610), ('maximum', 542), ('security', 770), ('state', 843), ('penitentiary', 632), ('focused', 326), ('mainly', 523), ('emerald', 252), ('city', 145), ('experimental', 287), ('section', 769), ('prison', 674), ('cells', 131), ('glass', 354), ('fronts', 336), ('face', 291), ('inwards', 442), ('privacy', 676), ('high', 400), ('agenda', 27), ('em', 251), ('home', 403), ('manyaryans', 534), ('muslin', 578), ('gangstas', 342), ('nations', 583), ('christians', 143), ('italians', 445), ('irish', 443), ('snuffles', 814), ('death', 198), ('stares', 838), ('podgy', 658), ('dealings', 197), ('shady', 782), ('agreements', 29), ('never', 588), ('far', 302), ('away', 69), ('would', 1000), ('say', 746), ('main', 522), ('appeal', 52), ('due', 240), ('fact', 292), ('goes', 357), ('shows', 794), ('dare', 190), ('forget', 329), ('pretty', 671), ('pictures', 644), ('painted', 621), ('mainstream', 524), ('audiences', 65), ('charm', 137), ('romance', 731), ('mess', 554), ('around', 57), ('ever', 272), ('saw', 745), ('nasty', 582), ('surrey', 871), ('ready', 694), ('watched', 971), ('developed', 210), ('taste', 880), ('got', 363), ('accustomed', 11), ('levels', 487), ('graphics', 366), ('injustice', 432), ('crooked', 180), ('guards', 375), ('whole', 983), ('sold', 817), ('nickel', 593), ('inmates', 433), ('kill', 459), ('order', 612), ('get', 347), ('well', 979), ('manner', 532), ('middle', 557), ('class', 146), ('turned', 938), ('birches', 91), ('lack', 469), ('street', 856), ('skill', 807), ('experience', 286), ('may', 543), ('become', 81), ('comfortable', 156), ('uncomfortable', 941), ('viewingthats', 954), ('touch', 923), ('darker', 192), ('side', 795), ('wonderful', 991), ('little', 497), ('production', 679), ('filling', 314), ('technique', 883), ('assuming', 61), ('oldtimebbc', 607), ('fashion', 303), ('gives', 352), ('comforting', 157), ('sometimes', 821), ('discomforting', 225), ('sense', 775), ('realism', 696), ('entire', 266), ('piece', 645), ('actors', 15), ('extremely', 289), ('chosen', 142), ('michael', 556), ('sheen', 786), ('polar', 661), ('voices', 958), ('pat', 630), ('truly', 933), ('see', 771), ('fearless', 307), ('editing', 245), ('guided', 377), ('references', 704), ('williams', 985), ('diary', 215), ('entries', 267), ('worth', 999), ('terrific', 889), ('written', 1005), ('performed', 638), ('wasteful', 968), ('great', 368), ('masters', 537), ('comedy', 154), ('life', 490), ('really', 698), ('comes', 155), ('things', 896), ('fantasy', 301), ('guard', 374), ('rather', 691), ('traditional', 926), ('dream', 236), ('remains', 708), ('solid', 818), ('disappears', 221), ('plays', 653), ('knowledge', 466), ('senses', 776), ('particularly', 628), ('concerning', 163), ('norton', 598), ('halliwell', 383), ('sets', 779), ('flat', 324), ('halliwells', 384), ('morals', 571), ('decorating', 203), ('every', 273), ('surface', 870), ('terribly', 888), ('done', 229), ('thought', 900), ('way', 974), ('spend', 829), ('time', 909), ('hot', 409), ('summer', 866), ('weekend', 976), ('sitting', 805), ('air', 32), ('conditioned', 165), ('theater', 893), ('lighthearted', 491), ('plot', 655), ('simplistic', 799), ('dialogue', 213), ('witty', 988), ('characters', 136), ('liable', 488), ('even', 270), ('bread', 108), ('suspected', 872), ('aerial', 24), ('killer', 460), ('disappointed', 222), ('realize', 697), ('match', 538), ('point', 659), ('risk', 728), ('addition', 19), ('proof', 683), ('wood', 992), ('allen', 35), ('still', 848), ('fully', 338), ('control', 172), ('style', 859), ('many', 533), ('us', 944), ('grown', 373), ('lovethis', 512), ('id', 420), ('laughed', 475), ('woods', 993), ('remedies', 709), ('years', 1007), ('decade', 199), ('give', 350), ('impressed', 427), ('scarlet', 751), ('johnson', 451), ('managed', 530), ('tone', 918), ('image', 423), ('jumped', 453), ('average', 66), ('spirited', 832), ('young', 1010), ('womanthis', 990), ('crown', 181), ('jewel', 450), ('career', 125), ('whittier', 982), ('devil', 212), ('wears', 975), ('trade', 925), ('interesting', 438), ('sherman', 788), ('friends', 335), ('basically', 79), ('family', 297), ('boy', 105), ('jake', 448), ('thinks', 899), ('combine', 151), ('closet', 148), ('parents', 625), ('fighting', 313), ('timethis', 911), ('movie', 574), ('slower', 811), ('soap', 815), ('opera', 611), ('suddenly', 864), ('decides', 201), ('ratio', 692), ('zombieok', 1011), ('going', 358), ('make', 526), ('film', 315), ('must', 579), ('decide', 200), ('thrilled', 903), ('drama', 234), ('watchable', 970), ('diverting', 228), ('arguing', 56), ('like', 492), ('real', 695), ('totally', 922), ('ruins', 736), ('expected', 285), ('boogeyman', 99), ('similar', 797), ('instead', 436), ('meaningless', 546), ('spots', 834), ('10', 0), ('playing', 652), ('descent', 207), ('shots', 792), ('ignore', 422), ('letter', 486), ('matters', 541), ('love', 510), ('money', 569), ('usually', 946), ('stunning', 858), ('watch', 969), ('mr', 576), ('matter', 540), ('offers', 604), ('vivid', 957), ('portrait', 663), ('human', 413), ('relations', 706), ('seems', 772), ('telling', 885), ('power', 667), ('success', 862), ('people', 633), ('different', 218), ('situations', 806), ('encounter', 254), ('variation', 948), ('arthur', 58), ('schnitzlers', 758), ('play', 649), ('theme', 894), ('director', 220), ('transfers', 927), ('action', 13), ('present', 670), ('new', 589), ('york', 1009), ('meet', 548), ('connect', 166), ('connected', 167), ('another', 46), ('next', 591), ('person', 640), ('know', 465), ('previous', 673), ('contact', 169), ('stylish', 860), ('sophisticated', 823), ('luxurious', 518), ('look', 503), ('taken', 876), ('live', 498), ('world', 997), ('habitatthe', 380), ('gets', 348), ('souls', 826), ('picture', 643), ('stages', 836), ('loneliness', 500), ('inhabit', 431), ('big', 90), ('best', 86), ('place', 646), ('find', 318), ('sincere', 802), ('fulfillment', 337), ('discern', 224), ('case', 128), ('encounterthe', 256), ('acting', 12), ('good', 361), ('direction', 219), ('steve', 847), ('buscemi', 117), ('rosary', 734), ('dawson', 196), ('carl', 127), ('lane', 471), ('imperial', 425), ('adrian', 21), ('greater', 369), ('rest', 718), ('talented', 878), ('cast', 129), ('come', 152), ('alive', 34), ('wish', 987), ('luck', 514), ('await', 67), ('anxiously', 47), ('work', 996), ('probably', 677), ('alliee', 36), ('favorite', 306), ('story', 853), ('helplessness', 396), ('sacrifice', 740), ('education', 246), ('noble', 595), ('cause', 130), ('preach', 668), ('boring', 100), ('old', 605), ('despite', 208), ('seen', 773), ('15', 2), ('times', 910), ('last', 472), ('25', 6), ('paul', 631), ('lupus', 517), ('performance', 636), ('brings', 112), ('tears', 882), ('eyes', 290), ('better', 87), ('davis', 195), ('sympathetic', 874), ('roles', 729), ('delight', 204), ('kiss', 464), ('grand', 364), ('says', 748), ('dressed', 237), ('midges', 558), ('children', 140), ('makes', 527), ('fun', 339), ('mothers', 572), ('slow', 810), ('awakening', 68), ('happening', 387), ('roof', 733), ('believable', 83), ('startling', 841), ('dozen', 232), ('thumbs', 904), ('sure', 869), ('resurrection', 719), ('dated', 193), ('seahunt', 767), ('series', 777), ('teach', 881), ('today', 915), ('bring', 111), ('back', 71), ('kid', 458), ('excitement', 283), ('grew', 371), ('black', 96), ('white', 981), ('gunsmoke', 378), ('hero', 398), ('weekyou', 978), ('vote', 959), ('comeback', 153), ('sea', 766), ('hunter', 417), ('need', 585), ('change', 134), ('pace', 618), ('water', 973), ('adventure', 23), ('thank', 892), ('outlet', 615), ('view', 953), ('viewpoint', 955), ('moviesso', 575), ('ole', 608), ('believe', 84), ('anna', 44), ('saywould', 749), ('nice', 592), ('read', 693), ('plus', 657), ('points', 660), ('rhymes', 723), ('lines', 496), ('let', 484), ('submit', 861), ('leave', 480), ('doubt', 231), ('quite', 689), ('lets', 485), ('amazing', 42), ('fresh', 333), ('innovative', 434), ('idea', 421), ('tired', 913), ('brilliant', 110), ('dropped', 238), ('1990', 4), ('funny', 340), ('anymore', 48), ('continued', 170), ('decline', 202), ('complete', 161), ('waste', 966), ('todayits', 916), ('disgraceful', 226), ('fallen', 296), ('writing', 1004), ('painfully', 620), ('bad', 73), ('performances', 637), ('almost', 37), ('mildly', 561), ('entertaining', 265), ('respite', 717), ('guesthosts', 376), ('hard', 389), ('creator', 177), ('handselected', 385), ('original', 613), ('also', 39), ('chose', 141), ('band', 76), ('backs', 72), ('followed', 327), ('recognize', 702), ('brilliance', 109), ('fit', 322), ('replace', 713), ('mediocrity', 547), ('felt', 310), ('stars', 839), ('respect', 716), ('made', 521), ('huge', 412), ('awful', 70), ('encouraged', 257), ('positive', 664), ('comments', 158), ('looking', 505), ('forward', 331), ('mistake', 566), ('950', 8), ('films', 316), ('worst', 998), ('pacing', 619), ('storyline', 854), ('soundtrack', 827), ('song', 822), ('lame', 470), ('country', 174), ('tune', 937), ('played', 650), ('less', 482), ('four', 332), ('looks', 506), ('cheap', 138), ('extreme', 288), ('rarely', 690), ('happy', 388), ('end', 258), ('credits', 178), ('prevents', 672), ('giving', 353), ('score', 761), ('harvey', 391), ('kettle', 456), ('least', 479), ('making', 528), ('bit', 93), ('effort', 248), ('obsessives', 602), ('gut', 379), ('wrenching', 1002), ('laughter', 476), ('hell', 394), ('mon', 568), ('liked', 493), ('camp', 121), ('phil', 642), ('alien', 33), ('quickly', 688), ('humour', 416), ('based', 78), ('address', 20), ('everything', 275), ('actual', 16), ('punchlinesat', 687), ('odd', 603), ('progressed', 681), ('jokes', 452), ('anymoreits', 49), ('low', 513), ('budget', 115), ('problem', 678), ('eventually', 271), ('lost', 507), ('interest', 437), ('imagine', 424), ('stoner', 852), ('currently', 183), ('partakingfor', 627), ('something', 820), ('try', 935), ('brother', 113), ('planet', 648), ('12', 1), ('came', 120), ('recall', 700), ('caries', 126), ('scene', 752), ('bird', 92), ('eating', 244), ('men', 550), ('dangling', 189), ('helplessly', 395), ('parachutes', 624), ('horror', 406), ('horrors', 407), ('cheese', 139), ('saturday', 742), ('afternoon', 26), ('formula', 330), ('monster', 570), ('type', 939), ('moves', 573), ('included', 429), ('beautiful', 80), ('woman', 989), ('might', 560), ('daughter', 194), ('professor', 680), ('resolution', 715), ('died', 216), ('care', 124), ('much', 577), ('romantic', 732), ('angle', 43), ('year', 1006), ('predictable', 669), ('plots', 656), ('unintentional', 943), ('humorous', 415), ('later', 473), ('psychic', 684), ('loved', 511), ('star', 837), ('janet', 449), ('sleigh', 809), ('bumped', 116), ('early', 243), ('sat', 741), ('took', 919), ('notice', 599), ('since', 801), ('screenwriters', 764), ('scar', 750), ('possible', 665), ('wellworn', 980), ('rules', 737), ('fan', 299), ('balls', 75), ('enjoyed', 262), ('postal', 666), ('maybe', 544), ('ball', 74), ('apparently', 51), ('bought', 101), ('rights', 727), ('cry', 182), ('long', 502), ('ago', 28), ('game', 341), ('finished', 320), ('killing', 461), ('mercy', 553), ('infiltration', 430), ('secret', 768), ('research', 714), ('laws', 477), ('located', 499), ('tropical', 931), ('island', 444), ('warned', 964), ('scheme', 755), ('together', 917), ('along', 38), ('legion', 481), ('schmucks', 756), ('feeling', 309), ('lonely', 501), ('invites', 440), ('three', 901), ('countrymen', 175), ('players', 651), ('names', 581), ('til', 906), ('schneider', 757), ('bier', 89), ('half', 382), ('moellerthree', 567), ('actually', 17), ('self', 774), ('tale', 877), ('jack', 446), ('yes', 1008), ('german', 346), ('hail', 381), ('bratwurst', 107), ('dukes', 241), ('however', 411), ('till', 907), ('adams', 18), ('complained', 159), ('staying', 845), ('true', 932), ('perspective', 641), ('dont', 230), ('looked', 504), ('kicking', 457), ('beyond', 88), ('demanded', 206), ('evil', 276), ('mad', 520), ('scientist', 760), ('dr', 233), ('trigger', 930), ('geneticallymutatedsoldiers', 344), ('gas', 343), ('performing', 639), ('topsecret', 921), ('reminds', 711), ('spoiled', 833), ('vancouver', 947), ('reason', 699), ('palm', 623), ('trees', 928), ('rich', 724), ('lumberjackwoods', 516), ('gone', 360), ('started', 840), ('mehehe', 549), ('cannot', 122), ('stay', 844), ('shenanigans', 787), ('delivers', 205), ('meaning', 545), ('suckthere', 863), ('mentioning', 552), ('imply', 426), ('areas', 55), ('boat', 98), ('cromedalbino', 179), ('squad', 835), ('enters', 264), ('laugh', 474), ('weeks', 977), ('scheisse', 754), ('poor', 662), ('simpletons', 798), ('take', 875), ('wife', 984), ('ahead', 30), ('bow', 102), ('annoying', 45), ('sidekick', 796), ('shoot', 790), ('minutes', 565), ('screen', 763), ('shakespeareshakespeare', 784), ('appreciate', 54), ('trying', 936), ('shakespeare', 783), ('masses', 536), ('ruin', 735), ('goods', 362), ('scottish', 762), ('certain', 132), ('rev', 721), ('bowler', 104), ('hence', 397), ('bowdlerization', 103), ('tried', 929), ('victoria', 951), ('brain', 106), ('improve', 428), ('perfection', 634), ('write', 1003), ('ten', 886), ('text', 891), ('english', 260), ('composition', 162), ('force', 328), ('keep', 455), ('saying', 747), ('cut', 184), ('fantastic', 300), ('prisoners', 675), ('famous', 298), ('george', 345), ('colonel', 150), ('roll', 730), ('man', 529), ('constant', 168), ('sorrow', 824), ('recommend', 703), ('everybody', 274), ('greetings', 370), ('bart', 77), ('kind', 462), ('drawn', 235), ('exotic', 284), ('amateurish', 41), ('unbelievable', 940), ('bits', 94), ('sort', 825), ('school', 759), ('project', 682), ('hosanna', 408), ('marquette', 535), ('thinking', 898), ('stock', 850), ('bizarre', 95), ('supposed', 868), ('midst', 559), ('town', 924), ('involved', 441), ('lessons', 483), ('learned', 478), ('insight', 435), ('tilted', 908), ('ridiculous', 725), ('lots', 509), ('skin', 808), ('intrigues', 439), ('videotaped', 952), ('nonsensewhat', 597), ('sexual', 781), ('relationship', 707), ('nowhere', 600), ('heterosexual', 399), ('encounters', 255), ('absurd', 9), ('dance', 188), ('stereotyped', 846), ('pass', 629), ('million', 563), ('miles', 562), ('wasted', 967), ('could', 173), ('spent', 830), ('starving', 842), ('aids', 31), ('africa', 25), ('simply', 800), ('fails', 294), ('capture', 123), ('flavor', 325), ('terror', 890), ('1963', 3), ('title', 914), ('diam', 214), ('nelson', 586), ('excellent', 280), ('always', 40), ('holds', 401), ('exception', 282), ('owen', 616), ('wilson', 986), ('feel', 308), ('character', 135), ('luke', 515), ('major', 525), ('fault', 304), ('version', 949), ('strayed', 855), ('shirley', 789), ('jackson', 447), ('attempts', 64), ('grandiose', 365), ('thrill', 902), ('earlier', 242), ('snazzier', 812), ('special', 828), ('effects', 247), ('enjoy', 261), ('friction', 334), ('older', 606), ('top', 920), ('horrible', 405), ('want', 962), ('continuous', 171), ('minute', 564), ('fight', 312), ('chance', 133), ('development', 211), ('busy', 118), ('running', 738), ('sword', 873), ('emotional', 253), ('attachment', 62), ('except', 281), ('machine', 519), ('wanted', 963), ('destroy', 209), ('blatantly', 97), ('stolen', 851), ('lot', 508), ('wars', 965), ('matrix', 539), ('examplesthe', 279), ('ghost', 349), ('final', 317), ('soda', 816), ('obey', 601), ('spider', 831), ('beginning', 82), ('attacked', 63), ('return', 720), ('kings', 463), ('elijah', 250), ('victim', 950), ('waiting', 961), ('hypnotics', 419), ('sting', 849), ('wraps', 1001), ('holland', 402), ('vs', 960), ('humans', 414), ('terminatorthere', 887), ('examples', 278), ('someone', 819), ('tell', 884), ('paris', 626), ('juvenile', 454), ('line', 495), ('rushed', 739), ('conclusion', 164), ('adult', 22), ('either', 249), ('disappointment', 223), ('save', 743), ('remember', 710), ('limit', 494), ('cinema', 144), ('dark', 191), ('places', 647), ('nervous', 587), ('7475', 7), ('dad', 185), ('sister', 804), ('newby', 590), ('berkshire', 85), ('england', 259), ('tigers', 905), ('snow', 813), ('appearance', 53), ('grizzly', 372), ('actor', 14), ('dan', 187), ('dagger', 186), ('think', 897), ('shot', 791), ('dies', 217), ('anyone', 50), ('knows', 467), ('etc', 269), ('please', 654), ('knowthe', 468), ('fitness', 323), ('club', 149), ('shame', 785), ('nearest', 584), ('20', 5), ('hear', 392), ('others', 614), ('singers', 803), ('nominated', 596), ('golden', 359), ('globe', 355), ('female', 311), ('renaissance', 712), ('painter', 622), ('mangled', 531), ('recognition', 701), ('complaint', 160), ('liberties', 489), ('facts', 293), ('perfectly', 635), ('fine', 319), ('accounts', 10), ('artist', 59), ('dishwaterdull', 227), ('script', 765), ('suppose', 867), ('enough', 263), ('naked', 580), ('hurriedly', 418), ('tapped', 879), ('summary', 865), ('artists', 60), ('saved', 744), ('couple', 176), ('hours', 410), ('favored', 305), ('gravity', 367)])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fa5254d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fc706238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequency: {'one': 25, 'reviews': 1, 'mentioned': 1, 'watching': 5, 'oz': 5, 'episode': 2, 'hooked': 1, 'right': 6, 'exactly': 3, 'happened': 1, 'metre': 1, 'first': 10, 'thing': 4, 'struck': 2, 'brutally': 1, 'unflinching': 1, 'scenes': 5, 'violence': 4, 'set': 2, 'word': 1, 'go': 7, 'trust': 1, 'show': 9, 'faint': 1, 'hearted': 1, 'timid': 1, 'pulls': 1, 'punched': 1, 'regards': 1, 'drugs': 1, 'sex': 2, 'hardware': 1, 'classic': 1, 'use': 3, 'words': 2, 'called': 2, 'nickname': 1, 'given': 1, 'onward': 1, 'maximum': 1, 'security': 1, 'state': 1, 'penitentiary': 1, 'focused': 1, 'mainly': 1, 'emerald': 1, 'city': 3, 'experimental': 1, 'section': 1, 'prison': 3, 'cells': 1, 'glass': 1, 'fronts': 1, 'face': 1, 'inwards': 1, 'privacy': 1, 'high': 3, 'agenda': 2, 'em': 1, 'home': 2, 'manyaryans': 1, 'muslin': 1, 'gangstas': 1, 'nations': 1, 'christians': 1, 'italians': 1, 'irish': 1, 'snuffles': 1, 'death': 1, 'stares': 1, 'podgy': 1, 'dealings': 1, 'shady': 1, 'agreements': 1, 'never': 5, 'far': 10, 'away': 3, 'would': 11, 'say': 6, 'main': 1, 'appeal': 2, 'due': 2, 'fact': 1, 'goes': 3, 'shows': 1, 'dare': 2, 'forget': 3, 'pretty': 6, 'pictures': 1, 'painted': 1, 'mainstream': 1, 'audiences': 1, 'charm': 1, 'romance': 1, 'mess': 1, 'around': 2, 'ever': 2, 'saw': 4, 'nasty': 2, 'surrey': 1, 'ready': 1, 'watched': 3, 'developed': 1, 'taste': 1, 'got': 4, 'accustomed': 1, 'levels': 1, 'graphics': 1, 'injustice': 1, 'crooked': 1, 'guards': 1, 'whole': 5, 'sold': 1, 'nickel': 1, 'inmates': 2, 'kill': 2, 'order': 1, 'get': 3, 'well': 6, 'manner': 1, 'middle': 1, 'class': 1, 'turned': 2, 'birches': 1, 'lack': 1, 'street': 1, 'skill': 1, 'experience': 2, 'may': 3, 'become': 3, 'comfortable': 1, 'uncomfortable': 1, 'viewingthats': 1, 'touch': 1, 'darker': 1, 'side': 1, 'wonderful': 2, 'little': 3, 'production': 2, 'filling': 1, 'technique': 2, 'assuming': 1, 'oldtimebbc': 1, 'fashion': 1, 'gives': 1, 'comforting': 1, 'sometimes': 1, 'discomforting': 1, 'sense': 1, 'realism': 2, 'entire': 1, 'piece': 2, 'actors': 2, 'extremely': 1, 'chosen': 1, 'michael': 2, 'sheen': 1, 'polar': 1, 'voices': 1, 'pat': 1, 'truly': 4, 'see': 9, 'fearless': 1, 'editing': 2, 'guided': 1, 'references': 1, 'williams': 1, 'diary': 1, 'entries': 1, 'worth': 2, 'terrific': 1, 'written': 1, 'performed': 1, 'wasteful': 1, 'great': 3, 'masters': 1, 'comedy': 3, 'life': 3, 'really': 4, 'comes': 1, 'things': 3, 'fantasy': 1, 'guard': 1, 'rather': 2, 'traditional': 1, 'dream': 1, 'remains': 1, 'solid': 1, 'disappears': 1, 'plays': 1, 'knowledge': 1, 'senses': 1, 'particularly': 2, 'concerning': 1, 'norton': 1, 'halliwell': 1, 'sets': 1, 'flat': 1, 'halliwells': 1, 'morals': 1, 'decorating': 1, 'every': 3, 'surface': 1, 'terribly': 1, 'done': 1, 'thought': 2, 'way': 5, 'spend': 1, 'time': 5, 'hot': 1, 'summer': 1, 'weekend': 1, 'sitting': 1, 'air': 4, 'conditioned': 1, 'theater': 1, 'lighthearted': 1, 'plot': 1, 'simplistic': 1, 'dialogue': 2, 'witty': 1, 'characters': 5, 'liable': 1, 'even': 5, 'bread': 1, 'suspected': 1, 'aerial': 1, 'killer': 1, 'disappointed': 2, 'realize': 2, 'match': 1, 'point': 3, 'risk': 1, 'addition': 1, 'proof': 1, 'wood': 2, 'allen': 1, 'still': 4, 'fully': 1, 'control': 1, 'style': 1, 'many': 4, 'us': 3, 'grown': 1, 'lovethis': 1, 'id': 1, 'laughed': 1, 'woods': 1, 'remedies': 1, 'years': 3, 'decade': 1, 'give': 6, 'impressed': 1, 'scarlet': 1, 'johnson': 1, 'managed': 1, 'tone': 1, 'image': 1, 'jumped': 1, 'average': 1, 'spirited': 1, 'young': 3, 'womanthis': 1, 'crown': 1, 'jewel': 1, 'career': 6, 'whittier': 1, 'devil': 1, 'wears': 1, 'trade': 2, 'interesting': 2, 'sherman': 1, 'friends': 1, 'basically': 1, 'family': 1, 'boy': 1, 'jake': 4, 'thinks': 1, 'combine': 1, 'closet': 2, 'parents': 3, 'fighting': 2, 'timethis': 1, 'movie': 23, 'slower': 1, 'soap': 1, 'opera': 1, 'suddenly': 1, 'decides': 1, 'ratio': 1, 'zombieok': 1, 'going': 3, 'make': 3, 'film': 26, 'must': 4, 'decide': 2, 'thrilled': 2, 'drama': 3, 'watchable': 1, 'diverting': 1, 'arguing': 1, 'like': 12, 'real': 3, 'totally': 1, 'ruins': 1, 'expected': 1, 'boogeyman': 1, 'similar': 3, 'instead': 2, 'meaningless': 1, 'spots': 1, '10': 3, 'playing': 2, 'descent': 1, 'shots': 1, 'ignore': 1, 'letter': 1, 'matters': 2, 'love': 4, 'money': 4, 'usually': 2, 'stunning': 1, 'watch': 2, 'mr': 5, 'matter': 2, 'offers': 1, 'vivid': 1, 'portrait': 1, 'human': 2, 'relations': 2, 'seems': 3, 'telling': 1, 'power': 1, 'success': 2, 'people': 6, 'different': 3, 'situations': 1, 'encounter': 1, 'variation': 1, 'arthur': 1, 'schnitzlers': 1, 'play': 3, 'theme': 2, 'director': 1, 'transfers': 1, 'action': 1, 'present': 1, 'new': 2, 'york': 1, 'meet': 1, 'connect': 1, 'connected': 1, 'another': 5, 'next': 2, 'person': 2, 'know': 4, 'previous': 1, 'contact': 1, 'stylish': 1, 'sophisticated': 1, 'luxurious': 1, 'look': 1, 'taken': 3, 'live': 2, 'world': 3, 'habitatthe': 1, 'gets': 4, 'souls': 1, 'picture': 2, 'stages': 1, 'loneliness': 1, 'inhabit': 1, 'big': 7, 'best': 2, 'place': 1, 'find': 5, 'sincere': 1, 'fulfillment': 1, 'discern': 1, 'case': 1, 'encounterthe': 1, 'acting': 3, 'good': 5, 'direction': 1, 'steve': 1, 'buscemi': 1, 'rosary': 1, 'dawson': 1, 'carl': 1, 'lane': 1, 'imperial': 1, 'adrian': 1, 'greater': 1, 'rest': 2, 'talented': 1, 'cast': 5, 'come': 2, 'alive': 1, 'wish': 1, 'luck': 1, 'await': 1, 'anxiously': 1, 'work': 4, 'probably': 2, 'alliee': 1, 'favorite': 2, 'story': 7, 'helplessness': 1, 'sacrifice': 1, 'education': 1, 'noble': 1, 'cause': 1, 'preach': 1, 'boring': 2, 'old': 4, 'despite': 1, 'seen': 4, '15': 1, 'times': 2, 'last': 1, '25': 1, 'paul': 1, 'lupus': 1, 'performance': 2, 'brings': 1, 'tears': 1, 'eyes': 1, 'better': 3, 'davis': 1, 'sympathetic': 1, 'roles': 2, 'delight': 1, 'kiss': 1, 'grand': 1, 'says': 1, 'dressed': 1, 'midges': 1, 'children': 3, 'makes': 3, 'fun': 1, 'mothers': 1, 'slow': 1, 'awakening': 1, 'happening': 1, 'roof': 1, 'believable': 1, 'startling': 1, 'dozen': 1, 'thumbs': 1, 'sure': 1, 'resurrection': 1, 'dated': 1, 'seahunt': 2, 'series': 1, 'teach': 1, 'today': 1, 'bring': 3, 'back': 2, 'kid': 2, 'excitement': 1, 'grew': 1, 'black': 1, 'white': 1, 'gunsmoke': 1, 'hero': 2, 'weekyou': 1, 'vote': 1, 'comeback': 1, 'sea': 2, 'hunter': 1, 'need': 1, 'change': 1, 'pace': 1, 'water': 1, 'adventure': 1, 'thank': 1, 'outlet': 1, 'view': 1, 'viewpoint': 1, 'moviesso': 1, 'ole': 1, 'believe': 3, 'anna': 4, 'saywould': 1, 'nice': 3, 'read': 1, 'plus': 1, 'points': 1, 'rhymes': 1, 'lines': 2, 'let': 2, 'submit': 1, 'leave': 1, 'doubt': 1, 'quite': 2, 'lets': 1, 'amazing': 1, 'fresh': 1, 'innovative': 1, 'idea': 1, 'tired': 2, 'brilliant': 2, 'dropped': 1, '1990': 1, 'funny': 3, 'anymore': 1, 'continued': 1, 'decline': 1, 'complete': 1, 'waste': 2, 'todayits': 1, 'disgraceful': 1, 'fallen': 1, 'writing': 1, 'painfully': 1, 'bad': 8, 'performances': 1, 'almost': 2, 'mildly': 1, 'entertaining': 1, 'respite': 1, 'guesthosts': 1, 'hard': 2, 'creator': 1, 'handselected': 1, 'original': 3, 'also': 2, 'chose': 1, 'band': 1, 'backs': 1, 'followed': 1, 'recognize': 1, 'brilliance': 1, 'fit': 1, 'replace': 1, 'mediocrity': 1, 'felt': 1, 'stars': 1, 'respect': 1, 'made': 6, 'huge': 1, 'awful': 5, 'encouraged': 1, 'positive': 1, 'comments': 1, 'looking': 1, 'forward': 1, 'mistake': 1, '950': 1, 'films': 6, 'worst': 1, 'pacing': 1, 'storyline': 2, 'soundtrack': 2, 'song': 1, 'lame': 1, 'country': 1, 'tune': 1, 'played': 4, 'less': 1, 'four': 1, 'looks': 1, 'cheap': 1, 'extreme': 1, 'rarely': 1, 'happy': 2, 'end': 4, 'credits': 1, 'prevents': 1, 'giving': 1, 'score': 1, 'harvey': 1, 'kettle': 2, 'least': 3, 'making': 3, 'bit': 1, 'effort': 1, 'obsessives': 1, 'gut': 1, 'wrenching': 1, 'laughter': 1, 'hell': 1, 'mon': 1, 'liked': 1, 'camp': 1, 'phil': 1, 'alien': 1, 'quickly': 1, 'humour': 1, 'based': 1, 'address': 2, 'everything': 2, 'actual': 2, 'punchlinesat': 1, 'odd': 1, 'progressed': 1, 'jokes': 1, 'anymoreits': 1, 'low': 1, 'budget': 1, 'problem': 1, 'eventually': 1, 'lost': 3, 'interest': 1, 'imagine': 1, 'stoner': 1, 'currently': 1, 'partakingfor': 1, 'something': 4, 'try': 1, 'brother': 2, 'planet': 1, '12': 2, 'came': 2, 'recall': 2, 'caries': 1, 'scene': 4, 'bird': 1, 'eating': 2, 'men': 1, 'dangling': 1, 'helplessly': 1, 'parachutes': 1, 'horror': 1, 'horrors': 1, 'cheese': 1, 'saturday': 1, 'afternoon': 1, 'formula': 2, 'monster': 3, 'type': 1, 'moves': 3, 'included': 1, 'beautiful': 1, 'woman': 1, 'might': 1, 'daughter': 1, 'professor': 1, 'resolution': 1, 'died': 1, 'care': 1, 'much': 3, 'romantic': 1, 'angle': 1, 'year': 2, 'predictable': 1, 'plots': 1, 'unintentional': 1, 'humorous': 1, 'later': 1, 'psychic': 1, 'loved': 1, 'star': 3, 'janet': 1, 'sleigh': 1, 'bumped': 1, 'early': 1, 'sat': 1, 'took': 2, 'notice': 1, 'since': 1, 'screenwriters': 1, 'scar': 1, 'possible': 1, 'wellworn': 1, 'rules': 1, 'fan': 2, 'balls': 2, 'enjoyed': 2, 'postal': 1, 'maybe': 1, 'ball': 5, 'apparently': 1, 'bought': 1, 'rights': 1, 'cry': 4, 'long': 1, 'ago': 1, 'game': 1, 'finished': 1, 'killing': 1, 'mercy': 1, 'infiltration': 1, 'secret': 1, 'research': 2, 'laws': 1, 'located': 1, 'tropical': 1, 'island': 2, 'warned': 1, 'scheme': 1, 'together': 1, 'along': 1, 'legion': 1, 'schmucks': 1, 'feeling': 1, 'lonely': 1, 'invites': 1, 'three': 3, 'countrymen': 1, 'players': 1, 'names': 2, 'til': 2, 'schneider': 2, 'bier': 2, 'half': 1, 'moellerthree': 1, 'actually': 1, 'self': 1, 'tale': 1, 'jack': 1, 'yes': 1, 'german': 1, 'hail': 1, 'bratwurst': 1, 'dukes': 1, 'however': 2, 'till': 1, 'adams': 2, 'complained': 1, 'staying': 1, 'true': 4, 'perspective': 1, 'dont': 1, 'looked': 1, 'kicking': 1, 'beyond': 2, 'demanded': 1, 'evil': 1, 'mad': 1, 'scientist': 1, 'dr': 1, 'trigger': 1, 'geneticallymutatedsoldiers': 1, 'gas': 2, 'performing': 1, 'topsecret': 1, 'reminds': 1, 'spoiled': 1, 'vancouver': 1, 'reason': 1, 'palm': 1, 'trees': 1, 'rich': 1, 'lumberjackwoods': 1, 'gone': 1, 'started': 1, 'mehehe': 1, 'cannot': 2, 'stay': 1, 'shenanigans': 1, 'delivers': 1, 'meaning': 1, 'suckthere': 1, 'mentioning': 1, 'imply': 1, 'areas': 1, 'boat': 1, 'cromedalbino': 1, 'squad': 1, 'enters': 1, 'laugh': 1, 'weeks': 1, 'scheisse': 1, 'poor': 1, 'simpletons': 1, 'take': 1, 'wife': 1, 'ahead': 1, 'bow': 1, 'annoying': 1, 'sidekick': 1, 'shoot': 1, 'minutes': 1, 'screen': 1, 'shakespeareshakespeare': 1, 'appreciate': 1, 'trying': 1, 'shakespeare': 2, 'masses': 1, 'ruin': 1, 'goods': 1, 'scottish': 1, 'certain': 1, 'rev': 1, 'bowler': 1, 'hence': 1, 'bowdlerization': 1, 'tried': 1, 'victoria': 1, 'brain': 1, 'improve': 1, 'perfection': 1, 'write': 2, 'ten': 1, 'text': 1, 'english': 1, 'composition': 1, 'force': 1, 'keep': 1, 'saying': 1, 'cut': 1, 'fantastic': 1, 'prisoners': 1, 'famous': 2, 'george': 1, 'colonel': 1, 'roll': 1, 'man': 1, 'constant': 1, 'sorrow': 1, 'recommend': 1, 'everybody': 2, 'greetings': 1, 'bart': 1, 'kind': 1, 'drawn': 1, 'exotic': 1, 'amateurish': 1, 'unbelievable': 1, 'bits': 1, 'sort': 1, 'school': 1, 'project': 1, 'hosanna': 1, 'marquette': 1, 'thinking': 1, 'stock': 1, 'bizarre': 2, 'supposed': 1, 'midst': 1, 'town': 1, 'involved': 1, 'lessons': 1, 'learned': 1, 'insight': 1, 'tilted': 1, 'ridiculous': 1, 'lots': 2, 'skin': 1, 'intrigues': 1, 'videotaped': 1, 'nonsensewhat': 1, 'sexual': 1, 'relationship': 1, 'nowhere': 1, 'heterosexual': 1, 'encounters': 1, 'absurd': 1, 'dance': 1, 'stereotyped': 1, 'pass': 1, 'million': 1, 'miles': 2, 'wasted': 1, 'could': 3, 'spent': 1, 'starving': 1, 'aids': 1, 'africa': 1, 'simply': 2, 'fails': 1, 'capture': 1, 'flavor': 1, 'terror': 2, '1963': 1, 'title': 1, 'diam': 1, 'nelson': 1, 'excellent': 1, 'always': 1, 'holds': 1, 'exception': 1, 'owen': 1, 'wilson': 1, 'feel': 1, 'character': 2, 'luke': 1, 'major': 1, 'fault': 1, 'version': 3, 'strayed': 1, 'shirley': 1, 'jackson': 1, 'attempts': 1, 'grandiose': 1, 'thrill': 1, 'earlier': 1, 'snazzier': 1, 'special': 1, 'effects': 1, 'enjoy': 1, 'friction': 1, 'older': 1, 'top': 1, 'horrible': 1, 'want': 3, 'continuous': 1, 'minute': 1, 'fight': 2, 'chance': 1, 'development': 1, 'busy': 1, 'running': 1, 'sword': 1, 'emotional': 1, 'attachment': 1, 'except': 1, 'machine': 3, 'wanted': 1, 'destroy': 1, 'blatantly': 1, 'stolen': 2, 'lot': 1, 'wars': 2, 'matrix': 2, 'examplesthe': 1, 'ghost': 1, 'final': 1, 'soda': 1, 'obey': 1, 'spider': 2, 'beginning': 1, 'attacked': 1, 'return': 1, 'kings': 1, 'elijah': 1, 'victim': 2, 'waiting': 1, 'hypnotics': 1, 'sting': 1, 'wraps': 1, 'holland': 1, 'vs': 1, 'humans': 1, 'terminatorthere': 1, 'examples': 1, 'someone': 1, 'tell': 1, 'paris': 2, 'juvenile': 2, 'line': 1, 'rushed': 1, 'conclusion': 1, 'adult': 1, 'either': 1, 'disappointment': 1, 'save': 1, 'remember': 1, 'limit': 1, 'cinema': 4, 'dark': 1, 'places': 1, 'nervous': 1, '7475': 1, 'dad': 1, 'sister': 1, 'newby': 2, 'berkshire': 1, 'england': 1, 'tigers': 2, 'snow': 1, 'appearance': 1, 'grizzly': 1, 'actor': 1, 'dan': 1, 'dagger': 1, 'think': 1, 'shot': 1, 'dies': 1, 'anyone': 1, 'knows': 1, 'etc': 1, 'please': 1, 'knowthe': 1, 'fitness': 1, 'club': 1, 'shame': 1, 'nearest': 1, '20': 1, 'hear': 1, 'others': 1, 'singers': 1, 'nominated': 1, 'golden': 1, 'globe': 1, 'female': 1, 'renaissance': 1, 'painter': 1, 'mangled': 1, 'recognition': 1, 'complaint': 1, 'liberties': 1, 'facts': 1, 'perfectly': 1, 'fine': 1, 'accounts': 1, 'artist': 1, 'dishwaterdull': 1, 'script': 1, 'suppose': 1, 'enough': 1, 'naked': 1, 'hurriedly': 1, 'tapped': 1, 'summary': 1, 'artists': 1, 'saved': 1, 'couple': 1, 'hours': 1, 'favored': 1, 'gravity': 1}\n"
     ]
    }
   ],
   "source": [
    "# Sum the columns of the BoW matrix to get word counts\n",
    "word_counts = bow.toarray().sum(axis=0)\n",
    "\n",
    "# Map the words to their total counts\n",
    "word_frequency = {word: word_counts[index] for word, index in cv.vocabulary_.items()}\n",
    "\n",
    "# Print the word frequency\n",
    "print(\"Word Frequency:\", word_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c3674e",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a7086030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0493a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf.fit_transform(data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "03b1a3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '12', '15', ..., 'york', 'young', 'zombieok'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d88dbbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>1963</th>\n",
       "      <th>1990</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>7475</th>\n",
       "      <th>950</th>\n",
       "      <th>absurd</th>\n",
       "      <th>...</th>\n",
       "      <th>wrenching</th>\n",
       "      <th>write</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zombieok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090302</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.087280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.093569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220865</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088201</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.069573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1012 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          10        12        15      1963      1990        20        25  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.087280  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.145646  0.000000  0.000000  0.000000  0.145646   \n",
       "6   0.093569  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.104116  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.222401  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  0.141329  0.000000  0.000000  0.000000   \n",
       "17  0.069573  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.118879  0.000000   \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        7475       950    absurd  ...  wrenching     write   writing  \\\n",
       "0   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.104116   \n",
       "8   0.000000  0.135849  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  ...   0.278457  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.000000  ...   0.000000  0.289189  0.000000   \n",
       "14  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.127014  ...   0.000000  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "18  0.118879  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000  ...   0.000000  0.000000  0.000000   \n",
       "\n",
       "     written      year     years       yes      york     young  zombieok  \n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1   0.105824  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.090302  0.000000  0.000000  0.090302  0.000000  \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.110038  \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.084505  0.000000  0.000000  \n",
       "5   0.000000  0.000000  0.115522  0.000000  0.000000  0.000000  0.000000  \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.000000  0.082582  0.000000  0.000000  0.000000  0.000000  \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.220865  0.000000  \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "11  0.000000  0.222401  0.000000  0.000000  0.000000  0.088201  0.000000  \n",
       "12  0.000000  0.000000  0.000000  0.058292  0.000000  0.000000  0.000000  \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "16  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[20 rows x 1012 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "tfidf_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
